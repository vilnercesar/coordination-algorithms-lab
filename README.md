# üì° Laborat√≥rio de Algoritmos de Coordena√ß√£o Distribu√≠da

Este projeto √© uma implementa√ß√£o pr√°tica de algoritmos cl√°ssicos de sistemas distribu√≠dos, desenvolvido em **Python (FastAPI)** e orquestrado via **Kubernetes (Minikube)**. O sistema simula um ambiente de processos independentes que precisam coordenar a√ß√µes, trocar mensagens e recuperar-se de falhas de forma aut√¥noma.

## üìã Funcionalidades Implementadas

O projeto unifica tr√™s mecanismos de coordena√ß√£o no mesmo c√≥digo:

* **Multicast com Ordena√ß√£o Total (Rel√≥gios de Lamport):** Garante que mensagens enviadas por diferentes processos sejam entregues na mesma ordem l√≥gica em todas as r√©plicas, utilizando filas de prioridade e confirma√ß√µes (ACKs).
* **Exclus√£o M√∫tua Centralizada:** Gerencia o acesso a um recurso cr√≠tico compartilhado utilizando um Coordenador central e filas de espera.
* **Elei√ß√£o de L√≠der (Algoritmo do Valent√£o/Bully):** Detecta a falha do coordenador e elege automaticamente um novo l√≠der (o processo com maior ID) para restaurar a consist√™ncia do sistema.

> **Nota:** O sistema tamb√©m possui funcionalidades de *Chaos Engineering* para simular atrasos de rede e testar a robustez dos algoritmos.

---

## üîå Principais Endpoints

| M√©todo | Endpoint | Descri√ß√£o |
| :--- | :--- | :--- |
| `POST` | `/initiate` | Envia uma mensagem em Multicast para o grupo (**Q1**). |
| `POST` | `/mutex/request_resource` | Solicita acesso √† se√ß√£o cr√≠tica ao l√≠der atual (**Q2**). |
| `POST` | `/mutex/release_resource` | Libera a se√ß√£o cr√≠tica, notificando o l√≠der (**Q2**). |
| `POST` | `/election/start` | **Gatilho Manual:** For√ßa o in√≠cio de um processo de elei√ß√£o de l√≠der (**Q3**). |
| `POST` | `/election/message` | **Interno:** Recebe mensagens do protocolo de elei√ß√£o (ELECTION, OK, COORDINATOR). |
| `POST` | `/config/delay` | Configura um atraso artificial no pr√≥ximo ACK para simular lentid√£o (Teste). |
| `GET` | `/health` | Retorna o ID do processo, o Rel√≥gio de Lamport atual e o ID do L√≠der reconhecido. |

---

## üõ†Ô∏è Pr√©-requisitos

Para executar este laborat√≥rio, voc√™ precisar√° de:

* [Docker](https://www.docker.com/) (Instalado e rodando)
* [Minikube](https://minikube.sigs.k8s.io/docs/start/) (Para simular o cluster Kubernetes localmente)
* `kubectl` (Ferramenta de linha de comando do Kubernetes)
* **Opcional:** `curl` ou um cliente HTTP (Postman/Insomnia) para testes.

---

## üöÄ Roteiro de Instala√ß√£o e Teste

Siga os passos abaixo para clonar, configurar e validar o sistema.

### 1. Instala√ß√£o e Build

Primeiro, clone o reposit√≥rio e inicie o ambiente:

```bash
# 1. Clone o projeto
git clone https://github.com/vilnercesar/coordination-algorithms-lab.git
cd coordination-algorithms-lab

# 2. Inicie o Minikube
minikube start

# 3. Conecte o terminal ao Docker do Minikube (CRUCIAL)
# Isso permite que o cluster "enxergue" a imagem que vamos criar
eval $(minikube docker-env)

# 4. Construa a imagem Docker
docker build -t distributed-system:v1 .

# 5. Implante os servi√ßos no Kubernetes
kubectl apply -f k8s.yaml

# 6. Aguarde at√© que todos os pods estejam com status 'Running'
kubectl get pods
```

### 2. Configura√ß√£o dos Terminais

Para visualizar os logs e interagir com o sistema, abra **4 terminais** (ou abas) diferentes:

* **Terminal 1 (T√∫nel P0):**
    ```bash
    kubectl port-forward deployment/process-0 5000:5000
    ```
* **Terminal 2 (T√∫nel P1):**
    ```bash
    kubectl port-forward deployment/process-1 5001:5000
    ```
* **Terminal 3 (T√∫nel P2):**
    ```bash
    kubectl port-forward deployment/process-2 5002:5000
    ```
* **Terminal 4 (Comandos):** Use este terminal para enviar as requisi√ß√µes `curl`.

> **Dica:** Para ver os logs em tempo real, voc√™ pode usar `kubectl logs -f deployment/process-X` em abas adicionais.

---

## üß™ Cen√°rios de Teste

Execute os comandos abaixo no **Terminal 4**.

### Cena 1: Multicast com Atraso (Ordena√ß√£o Total)
*Simula um processo lento. O sistema deve esperar o processo lento responder antes de entregar a mensagem a todos.*

```bash
# Configura atraso de 5s no Processo 1
curl -X POST http://localhost:5001/config/delay -H "Content-Type: application/json" -d '{"seconds": 5}'

# Envia mensagem via Processo 0
curl -X POST http://localhost:5000/initiate -H "Content-Type: application/json" -d '{"content": "Teste Q1"}'
```
**Resultado Esperado:** Os logs devem mostrar o recebimento imediato, uma pausa de 5s, e depois a mensagem `DELIVERED` aparecendo simultaneamente em todos os n√≥s.

### Cena 2: Exclus√£o M√∫tua (Concorr√™ncia)
*O L√≠der (P2) gerencia a fila. P0 pega o recurso, P1 tenta pegar e deve esperar.*

```bash
# P0 pede o recurso (Sucesso imediato)
curl -X POST http://localhost:5000/mutex/request_resource

# P1 pede o recurso (Deve ficar esperando/bloqueado)
curl -X POST http://localhost:5001/mutex/request_resource

# P0 libera o recurso (P1 deve receber acesso automaticamente agora)
curl -X POST http://localhost:5000/mutex/release_resource

# P1 libera para limpar
curl -X POST http://localhost:5001/mutex/release_resource
```

### Cena 3: Elei√ß√£o de L√≠der (Recupera√ß√£o de Falha)
*Simula a morte do L√≠der atual (P2). O sistema deve eleger o P1 (pr√≥ximo maior ID).*

```bash
# 1. "Matar" o L√≠der (Processo 2)
kubectl scale deployment process-2 --replicas=0

# 2. P0 tenta usar o sistema (Gatilho da falha)
# O c√≥digo detectar√° o erro de conex√£o e iniciar√° a elei√ß√£o automaticamente
curl -X POST http://localhost:5000/mutex/request_resource
```

**Resultado Esperado:** P0 detecta timeout do l√≠der, inicia elei√ß√£o. P1 responde, ganha a elei√ß√£o e se anuncia como novo l√≠der.

```bash
# 3. Verificar quem √© o novo l√≠der
curl http://localhost:5000/health
# Deve retornar: "leader": 1
```

---

## üõë Encerrando

Para parar e limpar o ambiente:

```bash
minikube delete
```
